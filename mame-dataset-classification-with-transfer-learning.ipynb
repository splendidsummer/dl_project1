{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nIn this notebook we use a TensorFlow and Keras with a DenseNet121 model pre-trained on ImageNet to classify the MAMe dataset with an accuracy of around 82%.","metadata":{}},{"cell_type":"markdown","source":"# Loading the dataset\nThe function ```load_mame``` reads the ```Mame_dataset.csv``` table and returns, for the train, validation and test subsets, a Pandas DataFrame containing the image filenames and their corresponding class (if ```dataframe=True```) or an array of filenames and a list of the corresponding classes (if ```dataframe=False```).\n\nThe DataFrame will be useful to use with Keras' ```ImageDataGenerator.flow_from_dataframe``` method.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\ndef load_mame(dataframe=False):\n    \"\"\" Load MAMe dataset data\n    Args:\n      dataframe (bool): whether to return a dataframe or an array of \n                        filenames and a list of labels\n      \n    Returns:\n      (x_train, y_train), (x_val, y_val), (x_test, y_test) if dataframe=False\n      or\n      df_train, df_val, df_test if dataframe=True\n    \"\"\"\n    INPUT_PATH = '/kaggle/input/'\n\n    # Load dataset table\n    dataset = pd.read_csv(os.path.join(INPUT_PATH, 'mame-dataset', 'MAMe_dataset.csv'))\n    \n    # Subset divisions\n    x_train_files = dataset.loc[dataset['Subset'] == 'train']['Image file'].tolist()\n    y_train_class = dataset.loc[dataset['Subset'] == 'train']['Medium'].tolist()\n\n    x_val_files = dataset.loc[dataset['Subset'] == 'val']['Image file'].tolist()\n    y_val_class = dataset.loc[dataset['Subset'] == 'val']['Medium'].tolist()\n\n    x_test_files = dataset.loc[dataset['Subset'] == 'test']['Image file'].tolist()\n    y_test_class = dataset.loc[dataset['Subset'] == 'test']['Medium'].tolist()\n\n    if dataframe:\n        train = pd.DataFrame({'filename': x_train_files, 'class': y_train_class})\n        val = pd.DataFrame({'filename': x_val_files, 'class': y_val_class})\n        test = pd.DataFrame({'filename': x_test_files, 'class': y_test_class})\n        \n        # Set full path\n        train['filename'] = train['filename'].transform(lambda x: INPUT_PATH + 'mame-dataset' + os.sep + 'data' + os.sep + x)\n        val['filename'] = val['filename'].transform(lambda x: INPUT_PATH + 'mame-dataset' + os.sep + 'data' + os.sep + x)\n        test['filename'] = test['filename'].transform(lambda x: INPUT_PATH + 'mame-dataset' + os.sep + 'data' + os.sep + x)\n        \n        return train, val, test\n    \n    else:\n        # Return list of filenames\n        x_train = [os.path.join(INPUT_PATH, 'mame-dataset', 'data', img_name) for img_name in x_train_files]\n        x_val = [os.path.join(INPUT_PATH, 'mame-dataset', 'data', img_name) for img_name in x_val_files]\n        x_test = [os.path.join(INPUT_PATH, 'mame-dataset', 'data', img_name) for img_name in x_test_files]\n\n        return (np.array(x_train), np.array(y_train_class)), (np.array(x_val), \n              np.array(y_val_class)), (np.array(x_test), np.array(y_test_class))\n    \n\ndf_train, df_val, df_test = load_mame(dataframe=True)\nprint(df_train.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot examples\nLet's visualize an example of each class:","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt\n\ndef show_images(img_df):\n    \"\"\" Show images\n    Plot a random sample of images for each of the class labels.\n    \n    Args:\n      img_df (DataFrame): DataFrame with a column 'filename' with image filenames and \n                          a colum 'class' with classification labels\n    \"\"\"\n    plt.figure(figsize=(20, 20))\n    i = 1\n    \n    classes = img_df['class'].unique().tolist()\n    for c in classes:\n        # Get a random sample of an instance with class c\n        filename = img_df[img_df['class']==c].sample(1)['filename'].values[0]\n        \n        # Plot image\n        plt.subplot(6, 5, i)\n        plt.imshow(load_img(filename))\n        plt.title(c, fontsize=16)\n        plt.axis('off')\n        i += 1\n                  \n    plt.show()\n                                                                                     \nshow_images(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-trained Model\nTo classify this dataset we will used a DenseNet121 model pre-trained on ImageNet. The same procedure can be applied to a different pre-trained model, but the DenseNet121 has been chosen for its relatively small size (number of parameters) and the accuracy obtained.\n\nThe pre-trained model will be fine-tuned by replacing the top layers of the network and training just the last two Convolutional blocks (Conv4-5), except for BatchNormalization layers. You can learn more about fine-tuning in this Keras tutorial: https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nnp.random.seed(2020)\n\nimport keras\nimport tensorflow as tf\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.models import Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization\nfrom keras import backend as k \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n\nprint('Using Keras version', keras.__version__)\nprint('Using TensorFlow version', tf.__version__)\n\n# Define some variables\nimg_width, img_height = 256, 256\nbatch_size = 128\nepochs = 100\npreprocessing_func = applications.densenet.preprocess_input\n\n#Â Load dataset\ndf_train, df_val, df_test = load_mame(dataframe=True)\nnum_classes = len(df_train['class'].unique())\n\n# Print information about loaded data\nprint('Training examples: {}\\n{}\\n'.format(len(df_train), df_train.head()))\nprint('Validation examples: {}\\n{}\\n'.format(len(df_val), df_val.head()))\n\n# Load pre-trained model\nbase_model = applications.DenseNet121(weights=\"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))  # pooling = max/avg\n\n# Freeze layers\n# Train all layers after first that are not a BatchNormalization layer\nfirst_to_train = 'conv5_block14_1_conv'\nbase_model.trainable = True\nset_trainable = False\nfor layer in base_model.layers:\n    if layer.name == first_to_train:\n        set_trainable = True\n        \n    if set_trainable and not isinstance(layer, BatchNormalization):\n        layer.trainable = True\n    else:\n        layer.trainable = False\n    \nprint('Number of initial layers: {}'.format(len(base_model.layers)))\n\n# Adding custom Layers \nx = base_model.output\nx = GlobalMaxPooling2D()(x)     # less features than Flatten\nx = Dropout(0.5)(x)\npredictions = Dense(num_classes, activation=\"softmax\", name='Predictions')(x)\n\n# Creating the final model \nmodel = Model(inputs = base_model.input, outputs = predictions)\n\n# Compile the model \nmodel.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr=0.001, epsilon=0.1, amsgrad=True), metrics=[\"accuracy\"])\n\n# Print model summary\nprint('Number of final layers: {}'.format(len(model.layers)))\n#print(model.summary())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation and generators\nWe use data augmentation on the train set and create generators for the train, validation and test set.","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n# Initiate the train and test generators with data Augumentation \ntrain_datagen = ImageDataGenerator(\n        preprocessing_function = preprocessing_func,\n        rotation_range = 30,\n        zoom_range = 0.2,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        shear_range = 0.2,        # TODO: increase shear - it is in degrees!\n        horizontal_flip = True,\n        fill_mode = \"nearest\")\n\ntest_datagen = ImageDataGenerator(preprocessing_function = preprocessing_func)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n        df_train,\n        target_size = (img_height, img_width),\n        batch_size = batch_size, \n        class_mode = \"categorical\",\n        validate_filenames=False)\n\nvalidation_generator = test_datagen.flow_from_dataframe(\n        df_val,\n        target_size = (img_height, img_width),\n        batch_size = batch_size,\n        shuffle = False, \n        class_mode = \"categorical\",\n        validate_filenames=False)\n\ntest_generator = test_datagen.flow_from_dataframe(\n        df_test,\n        target_size = (img_height, img_width),\n        batch_size = 1,\n        shuffle = False, \n        class_mode = \"categorical\",\n        validate_filenames=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model\nWe compile the model using the Adam optimizer and then fit the train generator.","metadata":{}},{"cell_type":"code","source":"# Save the model according to the conditions  \n#checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10, verbose=1, mode='auto', restore_best_weights=True)\n\n# Train the model \nt0 = time.time()\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VAL=validation_generator.n//validation_generator.batch_size\n\nhistory = model.fit_generator(\n                    generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=validation_generator,\n                    validation_steps=STEP_SIZE_VAL,\n                    epochs=epochs,\n                    use_multiprocessing=True,\n                    workers=6,\n                    callbacks = [early]\n                    )\n    \nprint('Model trained in {:.1f}min'.format((time.time()-t0)/60))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot training curves\nLet's plot the training and validation accurcay and loss curves.","metadata":{}},{"cell_type":"code","source":"def plot_training(history):\n    \"\"\" Plot training accuracy and loss curves\n    \n    Args:\n        history (dict): history dict obtained from fit function\n    \"\"\"\n    # Accuracy plot\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train','val'], loc='upper left')\n    plt.title('Training and validation accuracy')\n    plt.show()\n    \n    # Loss plot\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train','val'], loc='upper left')\n    plt.title('Training and validation loss')\n    plt.show()\n    \nplot_training(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate model\nNow we evaluate the model with the validation and data and output the classification report and plot a confusion matrix. After analyzing the results with the validation data, we could make decisions about our model. Only at the end we will evaluate our classifer with the test set.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import classification_report,confusion_matrix\n\ndef evaluate_model(model, eval_gen):\n    \"\"\" Evaluate given model and print results.\n    Show validation loss and accuracy, classification report and \n    confusion matrix.\n\n    Args:\n        model (model): model to evaluate\n        eval_gen (ImageDataGenerator): evaluation generator\n    \"\"\"\n    # Evaluate the model\n    eval_gen.reset()\n    score = model.evaluate(eval_gen, verbose=0)\n    print('\\nLoss:', score[0])\n    print('Accuracy:', score[1])\n    \n    # Confusion Matrix (validation subset)\n    eval_gen.reset()\n    pred = model.predict(eval_gen, verbose=0)\n\n    # Assign most probable label\n    predicted_class_indices = np.argmax(pred,axis=1)\n\n    # Get class labels\n    labels = (eval_gen.class_indices)\n    target_names = labels.keys()\n\n    # Plot statistics\n    print(classification_report(eval_gen.classes, predicted_class_indices, target_names=target_names))\n\n    cf_matrix = confusion_matrix(np.array(eval_gen.classes), predicted_class_indices)\n    fig, ax = plt.subplots(figsize=(13, 13)) \n    sns.heatmap(cf_matrix, annot=True, cmap='PuRd', cbar=False, square=True, xticklabels=target_names, yticklabels=target_names)\n    plt.show()\n    \nevaluate_model(model, validation_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test the model\nFinally, we evaluate the model on the test set.","metadata":{}},{"cell_type":"code","source":"evaluate_model(model, test_generator)","metadata":{},"execution_count":null,"outputs":[]}]}