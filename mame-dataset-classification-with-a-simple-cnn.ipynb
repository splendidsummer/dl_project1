{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nIn this notebook we present a simple CNN architecture to classify the MAMe dataset.\nWith 3 Convolutional Layers and two fully connected layers we can achieve a classification accuracy of around ~~75%~~ 65%.","metadata":{}},{"cell_type":"markdown","source":"# Loading the dataset\nThe function ```load_mame``` reads the ```Mame_dataset.csv``` table and returns, for the train, validation and test subsets, a Pandas DataFrame containing the image filenames and their corresponding class (if ```dataframe=True```) or an array of filenames and a list of the corresponding classes (if ```dataframe=False```).\n\nThe DataFrame will be useful to use with Keras' ```ImageDataGenerator.flow_from_dataframe``` method.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\ndef load_mame(dataframe=False):\n    \"\"\" Load MAMe dataset data\n    Args:\n      dataframe (bool): whether to return a dataframe or an array of \n                        filenames and a list of labels\n      \n    Returns:\n      (x_train, y_train), (x_val, y_val), (x_test, y_test) if dataframe=False\n      or\n      df_train, df_val, df_test if dataframe=True\n    \"\"\"\n    INPUT_PATH = '/kaggle/input/'\n\n    # Load dataset table\n    dataset = pd.read_csv(os.path.join(INPUT_PATH, 'mame-dataset', 'MAMe_dataset.csv'))\n    \n    # Subset divisions\n    x_train_files = dataset.loc[dataset['Subset'] == 'train']['Image file'].tolist()\n    y_train_class = dataset.loc[dataset['Subset'] == 'train']['Medium'].tolist()\n\n    x_val_files = dataset.loc[dataset['Subset'] == 'val']['Image file'].tolist()\n    y_val_class = dataset.loc[dataset['Subset'] == 'val']['Medium'].tolist()\n\n    x_test_files = dataset.loc[dataset['Subset'] == 'test']['Image file'].tolist()\n    y_test_class = dataset.loc[dataset['Subset'] == 'test']['Medium'].tolist()\n\n    if dataframe:\n        train = pd.DataFrame({'filename': x_train_files, 'class': y_train_class})\n        val = pd.DataFrame({'filename': x_val_files, 'class': y_val_class})\n        test = pd.DataFrame({'filename': x_test_files, 'class': y_test_class})\n        \n        # Set full path\n        train['filename'] = train['filename'].transform(lambda x: INPUT_PATH + 'mame-dataset' + os.sep + 'data' + os.sep + x)\n        val['filename'] = val['filename'].transform(lambda x: INPUT_PATH + 'mame-dataset' + os.sep + 'data' + os.sep + x)\n        test['filename'] = test['filename'].transform(lambda x: INPUT_PATH + 'mame-dataset' + os.sep + 'data' + os.sep + x)\n        \n        return train, val, test\n    \n    else:\n        # Return list of filenames\n        x_train = [os.path.join(INPUT_PATH, 'mame-dataset', 'data', img_name) for img_name in x_train_files]\n        x_val = [os.path.join(INPUT_PATH, 'mame-dataset', 'data', img_name) for img_name in x_val_files]\n        x_test = [os.path.join(INPUT_PATH, 'mame-dataset', 'data', img_name) for img_name in x_test_files]\n\n        return (np.array(x_train), np.array(y_train_class)), (np.array(x_val), \n              np.array(y_val_class)), (np.array(x_test), np.array(y_test_class))\n    \n\ndf_train, df_val, df_test = load_mame(dataframe=True)\nprint(df_train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot examples\nLet's visualize an example of each class:","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt\n\ndef show_images(img_df):\n    \"\"\" Show images\n    Plot a random sample of images for each of the class labels.\n    \n    Args:\n      img_df (DataFrame): DataFrame with a column 'filename' with image filenames and \n                          a colum 'class' with classification labels\n    \"\"\"\n    plt.figure(figsize=(20, 20))\n    i = 1\n    \n    classes = img_df['class'].unique().tolist()\n    for c in classes:\n        # Get a random sample of an instance with class c\n        filename = img_df[img_df['class']==c].sample(1)['filename'].values[0]\n        \n        # Plot image\n        plt.subplot(6, 5, i)\n        plt.imshow(load_img(filename))\n        plt.title(c, fontsize=16)\n        plt.axis('off')\n        i += 1\n                  \n    plt.show()\n                                                                                     \nshow_images(df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN\nTo classify this dataset will build a simle deep learning model based on convolutional layers. This is be done using TensorFlow and Keras.","metadata":{}},{"cell_type":"code","source":"import time\nimport keras\nimport tensorflow as tf\nfrom keras.optimizers import SGD, Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\n\n\nprint('Using Keras version', keras.__version__)\nprint('Using TensorFlow version', tf.__version__)\n\n# Initialize some variables\nimg_height, img_width = 256, 256\nn_channels = 3\ninput_shape = (img_height, img_width, n_channels)\nbatch_size = 128\n\n#Â Load dataset\ndf_train, df_val, df_test = load_mame(dataframe=True)\nnum_classes = len(df_train['class'].unique())\n\n# Model architecture\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(5, 5), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=input_shape, data_format='channels_last'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(num_classes, activation=(tf.nn.softmax)))\n\n# Print model summary\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation and generators\nWe use data augmentation on the train set and create generators for the train, validation and test set.","metadata":{}},{"cell_type":"code","source":"# Initiate the train and test generators with data Augumentation \ntrain_datagen = ImageDataGenerator(\n        rescale=1.0/255.0,\n        rotation_range = 30,\n        zoom_range = 0.2,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        shear_range = 0.2,\n        horizontal_flip = True,\n        fill_mode = \"nearest\")\n\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n        df_train,\n        target_size = (img_height, img_width),\n        batch_size = batch_size, \n        class_mode = \"categorical\",\n        validate_filenames=False)\n\nvalidation_generator = test_datagen.flow_from_dataframe(\n        df_val,\n        target_size = (img_height, img_width),\n        batch_size = batch_size,\n        shuffle = False, \n        class_mode = \"categorical\",\n        validate_filenames=False)\n\ntest_generator = test_datagen.flow_from_dataframe(\n        df_test,\n        target_size = (img_height, img_width),\n        batch_size = 1,\n        shuffle = False, \n        class_mode = \"categorical\",\n        validate_filenames=False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model\nWe compile the model using the Adam optimizer and then fit the train generator.","metadata":{}},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.001, epsilon=0.1, amsgrad=True), metrics=[\"accuracy\"])\n\n# Use early stopping\nearly = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto', restore_best_weights=True)\n\n# Train the model \nt0 = time.time()\nepochs = 100\n\nt0 = time.time()\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VAL=validation_generator.n//validation_generator.batch_size\n    \nhistory = model.fit(x=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=validation_generator,\n                    validation_steps=STEP_SIZE_VAL,\n                    epochs=epochs,\n                    use_multiprocessing=True,\n                    workers=6,\n                    callbacks = [early]\n                    )\n    \nprint('Model trained in {:.1f}min'.format((time.time()-t0)/60))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot training curves\nLet's plot the training and validation accurcay and loss curves.","metadata":{}},{"cell_type":"code","source":"def plot_training(history):\n    \"\"\" Plot training accuracy and loss curves\n    \n    Args:\n        history (dict): history dict obtained from fit function\n    \"\"\"\n    # Accuracy plot\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train','val'], loc='upper left')\n    plt.title('Training and validation accuracy')\n    plt.show()\n    \n    # Loss plot\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train','val'], loc='upper left')\n    plt.title('Training and validation loss')\n    plt.show()\n    \nplot_training(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate model\nNow we evaluate the model with the validation and data and output the classification report and plot a confusion matrix. After analyzing the results with the validation data, we could make decisions about our model. Only at the end we will evaluate our classifer with the test set.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import classification_report,confusion_matrix\n\ndef evaluate_model(model, eval_gen):\n    \"\"\" Evaluate given model and print results.\n    Show validation loss and accuracy, classification report and \n    confusion matrix.\n\n    Args:\n        model (model): model to evaluate\n        eval_gen (ImageDataGenerator): evaluation generator\n    \"\"\"\n    # Evaluate the model\n    eval_gen.reset()\n    score = model.evaluate(eval_gen, verbose=0)\n    print('\\nLoss:', score[0])\n    print('Accuracy:', score[1])\n    \n    # Confusion Matrix (validation subset)\n    eval_gen.reset()\n    pred = model.predict(eval_gen, verbose=0)\n\n    # Assign most probable label\n    predicted_class_indices = np.argmax(pred,axis=1)\n\n    # Get class labels\n    labels = (eval_gen.class_indices)\n    target_names = labels.keys()\n\n    # Plot statistics\n    print(classification_report(eval_gen.classes, predicted_class_indices, target_names=target_names))\n\n    cf_matrix = confusion_matrix(np.array(eval_gen.classes), predicted_class_indices)\n    fig, ax = plt.subplots(figsize=(13, 13)) \n    sns.heatmap(cf_matrix, annot=True, cmap='PuRd', cbar=False, square=True, xticklabels=target_names, yticklabels=target_names)\n    plt.show()\n    \nevaluate_model(model, validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test the model\nFinally, we evaluate the model on the test set.","metadata":{}},{"cell_type":"code","source":"evaluate_model(model, test_generator)","metadata":{},"execution_count":null,"outputs":[]}]}